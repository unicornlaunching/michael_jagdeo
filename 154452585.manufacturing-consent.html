<h6>Author: Michael Jagdeo | Blockface | <a href="http://www.twitter.com/attractfund1ng">attractfund1ng</a></h6><h6>Contributors: Mnemomeme, Fratrilogos, Oma Cox, BeatCheek, Rocky Nguyen, Seraph_Notitia, Quinn C. Martin, Potato Stu, Eileen Jan, Ayden Springer, Matios Berhe, Liminal Snake</h6><h6>Github: <a href="https://github.com/unicornlaunching/promptlikeanegyptian">https://github.com/unicornlaunching/promptlikeanegyptian</a></h6><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png 1456w" sizes="100vw"><img src="https://substack-post-media.s3.amazonaws.com/public/images/b94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png" width="960" height="540" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/b94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:540,&quot;width&quot;:960,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:246699,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb94f85e1-954d-448f-bb02-97b595bc13a1_960x540.png 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><h2>Background</h2><p><a href="https://arxiv.org/pdf/2406.06608">The Prompt Report: A Systematic Survey of Prompting Techniques</a> (June 2024), claimed the following:</p><blockquote><p>We present a detailed vocabulary of 33 vocabulary terms, a taxonomy of 58 LLM prompting techniques, and 40 techniques for other modalities. Additionally, we provide best practices and guidelines for prompt engineering, including advice for prompting engineering ChatGPT and other state-of-the-art (SOTA) LLMs. We further present a meta-analysis of the entire literature on natural language prefix-prompting. As a culmination of these efforts, this paper presents the most comprehensive survey on prompt engineering to date.</p></blockquote><h2>Motivation</h2><p>That paper overlooked the most powerful way to manufacture consent from LLMs, namely, prompting with propositional, predicate, and modal logic.</p><h2>The Last 100 Years Of Math</h2><p>At the turn of the 20th century, Hilbert proposes a bunch of unsolved problems in math. Standing on the shoulders of giants like Frege, Whitehead &amp; Russell write Principia Mathematica (named after Newton’s Principia), seeking to create a cathedral of logic. Godel proves you can’t do it.</p><p>As a result of Godel’s anti-thesis to the Princiipia Mathematica, Turing and Church create the Church-Turing Thesis as a result of Godel’s discoveries. Chomsky and Von Neuemann ensue to create software development languages.</p><h2>Motivation II</h2><p>The reason that people don't get what they want when they prompt LLMs is they're using the wrong language. They use natural language, i.e. sentences. The problem is, LLMs must translate these user queries into forms that the LLM can parse. By using logical expressions leveraging propositional, predicate, and modal logic, we can create a significantly better quality of result while reducing token usage across all LLMs</p><h2>Next Time You Prompt...</h2><p>Try starting with this prompt:</p><blockquote><p>I'd like to have a conversation with you, where at every step we update a logical expression that leverages predicate propositional and modal logic.</p></blockquote><h2>Rationale</h2><p>Prompting with predicate and propositional and modal logic offers a more precise and structured approach compared to natural language, leading to focused outputs with minimal token usage. Unlike natural language prompts, which can introduce ambiguity and require longer explanations to clarify intent, logic-based prompts reduce redundancy and optimize both computational efficiency and output quality. By expressing queries through formalized logical structures, we minimize unnecessary complexity, making interactions with Large Language Models (LLMs) more effective. This paper explores how leveraging predicate and propositional logic in prompt engineering can significantly improve response relevance, clarity, and performance. Furthermore, we discuss novel methods for implementing these approaches, including the development of predicate and propositional logic pre-processors that can optimize token usage, improve response quality, and reduce computational overhead. These advancements provide a more efficient method for engaging with LLMs, resulting in significant cost savings across compute, network, storage, bandwidth, and AI inference latency. These findings work with ALL LLMs.</p>